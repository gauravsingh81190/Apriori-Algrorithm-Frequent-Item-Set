{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "advisory-child",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "---------------------Configuration details---------------------\n",
      "\n",
      "\tsupport : 0.5\n",
      "\tconfidence : 0.8\n",
      "\tdatasetfile : /Users/gksingh/Downloads/Apriori/data/items.csv\n",
      "\tnum_items : 8\n",
      "\tnum_transactions : 8\n",
      "\n",
      "-----------------------------SUPPORT FOR EACH LEVEL -------------\n",
      "\n",
      "                items  count  support\n",
      "0            (banana)      4    0.500\n",
      "1              (pear)      7    0.875\n",
      "2               (fig)      6    0.750\n",
      "3            (orange)      4    0.500\n",
      "4             (water)      5    0.625\n",
      "5         (pear, fig)      5    0.625\n",
      "6       (pear, water)      5    0.625\n",
      "7        (fig, water)      4    0.500\n",
      "8  (pear, water, fig)      4    0.500\n",
      "\n",
      "---------------------------ASSOCIATIONS AND CONFIDENCES------------\n",
      "\n",
      "             full_key    predecessor  support_pred    successor  support_suc  support_full_key  confidence\n",
      "0         (pear, fig)          (fig)         0.750       (pear)        0.875             0.625    0.833333\n",
      "1       (pear, water)        (water)         0.625       (pear)        0.875             0.625    1.000000\n",
      "2        (fig, water)        (water)         0.625        (fig)        0.750             0.500    0.800000\n",
      "3  (pear, water, fig)        (water)         0.625  (pear, fig)        0.625             0.500    0.800000\n",
      "4  (pear, water, fig)  (pear, water)         0.625        (fig)        0.750             0.500    0.800000\n",
      "5  (pear, water, fig)    (pear, fig)         0.625      (water)        0.625             0.500    0.800000\n",
      "6  (pear, water, fig)   (fig, water)         0.500       (pear)        0.875             0.500    1.000000\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "import os\n",
    "import pandas as pd\n",
    "from optparse import OptionParser\n",
    "\n",
    "# This function will recursively generate all subset of specified length from a given Set.\n",
    "def genCombinatrics(itemset, i, el, cur, ans):\n",
    "    if(el == 0):\n",
    "        ans.append(tuple(cur))\n",
    "        return\n",
    "\n",
    "    rl = len(itemset) - i;\n",
    "    if(rl < el):\n",
    "        return\n",
    "    \n",
    "    newcur = []\n",
    "    newcur.extend(cur)\n",
    "    newcur.append(itemset[i])\n",
    "    genCombinatrics(itemset, i + 1, el - 1, newcur, ans)\n",
    "    genCombinatrics(itemset, i + 1, el, cur, ans)\n",
    "\n",
    "\n",
    "def getCombinatrics(itemset, el):\n",
    "    ans = []\n",
    "    if(el > 0):\n",
    "        genCombinatrics(itemset, 0, el, [], ans)\n",
    "    return ans\n",
    "\n",
    "\n",
    "#This function will generate all association for a given set.\n",
    "def genAssocs(itemset):\n",
    "    L = len(itemset)\n",
    "    ans = []\n",
    "    for i in range(1, L):\n",
    "        for s1 in getCombinatrics(itemset, i):\n",
    "            s2 = tuple(set(itemset) - set(s1))\n",
    "            ans.append((s1, s2))\n",
    "            #print(\"%s -> %s\"%(s1, s2))\n",
    "    return ans\n",
    "\n",
    "def getItemTransMap(trans):\n",
    "    items = {}\n",
    "    for tid in trans:\n",
    "        values = trans[tid]\n",
    "        for item in values:\n",
    "            if item not in items:\n",
    "                items[item] = set()\n",
    "            items[item].add(tid)\n",
    "    return items\n",
    "\n",
    "def EvalAssociations(trans, L, C, maxi, min_confidence):\n",
    "    N = len(trans)\n",
    "    for j in range(1, maxi):\n",
    "        if j > 1:\n",
    "            itemsets = list(L[j]) \n",
    "            for itemset in itemsets: \n",
    "                assoc = genAssocs(list(itemset))\n",
    "                L[j][itemset]['assocs'] = []\n",
    "                for r in assoc:\n",
    "                    A = frozenset(r[0])\n",
    "                    B = frozenset(r[1])\n",
    "                    # For A->B length1 means size of length of (TransactionA U TransactionB)\n",
    "                    # lengthB means sizeof TransactionA for which we must to corresponding L item\n",
    "                    length1 = len(L[j][itemset]['trans'])\n",
    "                    length2 = len(L[len(A)][A]['trans'])\n",
    "                    length3 = len(L[len(B)][B]['trans'])\n",
    "                    length4 = len(L[j][itemset]['trans'])\n",
    "                    if length1/length2 >= min_confidence:\n",
    "                        L[j][itemset]['assocs'].append({ 'p' : { 'e' : A, 's' : length2/N },  \n",
    "                                                         's' : { 'e' : B, 's' : length3/N },\n",
    "                                                        'confidence' : length1/length2, \n",
    "                                                        'support' : length4/N})    \n",
    "\n",
    "\n",
    "def exec_apriory(transactions, min_support, min_confidence, L, C):\n",
    "    items = getItemTransMap(transactions)\n",
    "    i = 0\n",
    "    \n",
    "    while i == 0 or len(L[i]) != 0:\n",
    "        i = i + 1\n",
    "        C[i] = {}\n",
    "        L[i] = {}\n",
    "  \n",
    "        if i == 1:\n",
    "            for item in items:\n",
    "                C[i][frozenset([item])] = { 'support' : float(len(items[item]))/len(transactions), 'trans' : frozenset(items[item]) }\n",
    "        else:\n",
    "\n",
    "            length = len(L[i - 1])\n",
    "            itemsets = list(L[i - 1])\n",
    "\n",
    "            for j in range(0, len(itemsets)):\n",
    "                for k in range(j + 1, len(itemsets)):\n",
    "                    itemset = itemsets[j].union(itemsets[k])\n",
    "                    if ((itemset not in C[i]) and (len(itemset) == i)):\n",
    "                        transj = L[i - 1][itemsets[j]]['trans']\n",
    "                        transk = L[i - 1][itemsets[k]]['trans'] \n",
    "                        transi = transj - ( transj - transk )\n",
    "                        C[i][itemset] = { 'support' : float(len(transi))/len(transactions), 'trans' : transi } \n",
    "                         \n",
    "        for itemset in C[i]:\n",
    "            if C[i][itemset]['support'] >= min_support:\n",
    "                L[i][itemset] = C[i][itemset] \n",
    "  \n",
    "    del L[i] \n",
    "    EvalAssociations(transactions, L, C, i, min_confidence)  \n",
    "\n",
    "def print_result(L, C, NT, NI, min_support, min_confidence, fileName):\n",
    "    maxi = 0\n",
    "    for i in L:\n",
    "        if(maxi < i):\n",
    "            maxi = i\n",
    "\n",
    "\n",
    "    print(\"\\n---------------------Configuration details---------------------\\n\")\n",
    "\n",
    "    print(\"\\tsupport : %s\"%(min_support))\n",
    "    print(\"\\tconfidence : %s\"%(min_confidence))\n",
    "    print(\"\\tdatasetfile : %s\"%(fileName))\n",
    "    print(\"\\tnum_items : %s\"%(NI))\n",
    "    print(\"\\tnum_transactions : %s\"%(NT))\n",
    "\n",
    "\n",
    "    print(\"\\n-----------------------------SUPPORT FOR EACH LEVEL -------------\\n\")\n",
    "\n",
    "    cols = [ 'items', 'count', 'support']\n",
    "    df_data = {\n",
    "                cols[0]: [],    \n",
    "                cols[1]: [],    \n",
    "                cols[2]: []    \n",
    "              } \n",
    "\n",
    "    for i in range(1, maxi + 1):\n",
    "        for itemset in L[i]:\n",
    "            df_data[cols[0]].append(itemset)\n",
    "            df_data[cols[1]].append(len(L[i][itemset]['trans']))\n",
    "            df_data[cols[2]].append(L[i][itemset]['support'])\n",
    "\n",
    "    print(pd.DataFrame(df_data).to_string())\n",
    "\n",
    "\n",
    "    print(\"\\n---------------------------ASSOCIATIONS AND CONFIDENCES------------\\n\")\n",
    "\n",
    "\n",
    "    cols = [ 'full_key', 'predecessor', 'support_pred', 'successor', 'support_suc', 'support_full_key', 'confidence' ]\n",
    "\n",
    "    df_data  = {\n",
    "                    cols[0] : [],\n",
    "                    cols[1] : [],\n",
    "                    cols[2] : [],\n",
    "                    cols[3] : [],\n",
    "                    cols[4] : [],\n",
    "                    cols[5] : [],\n",
    "                    cols[6] : []\n",
    "               }\n",
    "\n",
    "    for i in range(1, maxi + 1):\n",
    "        for itemset in L[i]:\n",
    "            values = L[i][itemset]\n",
    "            if 'assocs' in values:\n",
    "                assocs = values['assocs']\n",
    "                for assoc in assocs:\n",
    "                    fk = itemset\n",
    "                    sfk = assoc['support'] \n",
    "                    p  = assoc['p']['e']\n",
    "                    sp = assoc['p']['s']\n",
    "                    s  = assoc['s']['e']\n",
    "                    ss = assoc['s']['s']\n",
    "                    c  = assoc['confidence']\n",
    "                    df_data[cols[0]].append(fk) \n",
    "                    df_data[cols[1]].append(p) \n",
    "                    df_data[cols[2]].append(sp) \n",
    "                    df_data[cols[3]].append(s) \n",
    "                    df_data[cols[4]].append(ss) \n",
    "                    df_data[cols[5]].append(sfk) \n",
    "                    df_data[cols[6]].append(c) \n",
    "\n",
    "    print(pd.DataFrame(df_data).to_string())\n",
    "    \n",
    "def print_transactions(trans):\n",
    "    for key in trans:\n",
    "        print('%s:%s'%(key, trans[key]))\n",
    "\n",
    "\n",
    "def run_apriory(fileName, min_support, min_confidence):\n",
    "    trans = {}\n",
    "    itemset = set()\n",
    "    i = 1\n",
    "    with open(fileName, \"r\") as fp:\n",
    "        lines = fp.readlines()\n",
    "        for line in lines:\n",
    "            key = 'T%d'%(i)\n",
    "            i = i + 1\n",
    "            items = [x.strip() for x in line.split(',')]\n",
    "            trans[key] = items\n",
    "            itemset = itemset.union(items)\n",
    "\n",
    "    #print_transactions(trans) \n",
    "    L = {}\n",
    "    C = {}\n",
    "    exec_apriory(trans, min_support, min_confidence, L, C)\n",
    "    print_result(L, C, len(trans), len(itemset), min_support, min_confidence, fileName)    \n",
    "\n",
    "    \n",
    "if __name__ == '__main__':\n",
    "    fileName = './data/items.csv'\n",
    "    min_support = 0.5\n",
    "    min_confidence = 0.8\n",
    "    fileName = os.path.abspath(fileName)    \n",
    "    run_apriory(fileName, min_support, min_confidence)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "divine-watershed",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
